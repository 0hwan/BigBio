{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9장 Recommendation Engines Using MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추천 시스템이란 \n",
    "\n",
    "아마존에서는 \"Frequently Bought Together\"(아이템기반 추천) 과 \"Customers Who Bought This Item Also Bought\"(사용자기반 추천)의 여러 가지 추천 아이템을 보여줌.\n",
    "\n",
    "https://www.amazon.com/Data-Algorithms-Recipes-Scaling-Hadoop/dp/1491906189/ref=sr_1_1?ie=UTF8&qid=1477648946&sr=8-1&keywords=data+algorithms\n",
    "\n",
    "![](spark09_04.jpg)\n",
    "\n",
    "\n",
    "추천 엔진과 시스템은 사용자에게 아래와 같은 사용자 경험을 증진시켜줌.\n",
    "- 사용자에게 찾는 정보를 조언해줌.\n",
    "- 아이템(상품)을 검색과 네비게이션을 시간을 줄어줌.\n",
    "- 사이트에 자주 방문하도록 만족도을 올려줌.\n",
    "\n",
    "추천 엔진과 시스템의 목적\n",
    "- 사용자가 아직 사지 않은 아이템을 추천\n",
    "- 사용자가 생각지도 못한 영화나 책을 추천\n",
    "- 사용자가 방문하지 않은 음식점이나 장소 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friendship connection\n",
    "\n",
    "![](spark09_01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](spark09_02.jpg)\n",
    "\n",
    "- friends2.txt\n",
    "```\n",
    "1 2,3,4,5,6,7,8\n",
    "2 1,3,4,5,7\n",
    "3 1,2\n",
    "4 1,2,6\n",
    "5 1,2\n",
    "6 1,4\n",
    "7 1,2\n",
    "8 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output \n",
    "\n",
    "- USER :  F(M: [I1, I2, I3, ...]), ...\n",
    "    - F : USER에게 친구로 추천하는 사람의 ID\n",
    "    - M : 같이 친구의 명수 \n",
    "    - I1, I2, I3,  : 같이 친구인 사람의 ID\n",
    "\n",
    "```\n",
    "4: 3 (2: [1, 2]),5 (2: [1, 2]),7 (2: [1, 2]),8 (1: [1]),\n",
    "2: 6 (2: [1, 4]),8 (1: [1]),\n",
    "6: 2 (2: [1, 4]),3 (1: [1]),5 (1: [1]),7 (1: [1]),8 (1: [1]),\n",
    "8: 2 (1: [1]),3 (1: [1]),4 (1: [1]),5 (1: [1]),6 (1: [1]),7 (1: [1]),\n",
    "3: 4 (2: [1, 2]),5 (2: [1, 2]),6 (1: [1]),7 (2: [1, 2]),8 (1: [1]),\n",
    "1:\n",
    "7: 3 (2: [1, 2]),4 (2: [1, 2]),5 (2: [1, 2]),6 (1: [1]),8 (1: [1]),\n",
    "5: 3 (2: [1, 2]),4 (2: [1, 2]),6 (1: [1]),7 (2: [1, 2]),8 (1: [1]),\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Spark Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](spark09_03.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a Spark context object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f8e5db3da50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext() \n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Read the HDFS input file and create an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records = sc.textFile(\"friends2.txt\", 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug0 record: 1\t2,3,4,5,6,7,8\n",
      "debug0 record: 2\t1,3,4,5,7\n",
      "debug0 record: 3\t1,2\n",
      "debug0 record: 4\t1,2,6\n",
      "debug0 record: 5\t1,2\n",
      "debug0 record: 6\t1,4\n",
      "debug0 record: 7\t1,2\n",
      "debug0 record: 8\t1\n"
     ]
    }
   ],
   "source": [
    "for t in records.collect():\n",
    "    print \"debug0 record:\", t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement the map() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pairs( record ) :\n",
    "    # // record=<person><TAB><friend1><,><friend2><,><friend3><,>...\n",
    "    tokens = record.split(\"\\t\")\n",
    "    person = long( tokens[0] )\n",
    "    friendsAsString = tokens[1]\n",
    "    friendsTokenized = friendsAsString.split(\",\");\n",
    "    \n",
    "    friends = []  ## LIST형\n",
    "    mapperOutput = [] ## LIST형\n",
    "    for friendAsString in  friendsTokenized :\n",
    "        toUser = long( friendAsString )\n",
    "        friends.append( toUser  ) \n",
    "        directFriend = ( toUser, -1L )  # 튜플형\n",
    "        mapperOutput.append( ( person, directFriend )  )\n",
    "        \n",
    "    for i  in range( len(friends) )  :\n",
    "        for j in range( i+1,  len(friends) )  :\n",
    "            possibleFriend1 = ( friends[j], person )\n",
    "            mapperOutput.append( (friends[i], possibleFriend1)  ) \n",
    "            \n",
    "            possibleFriend2 = ( friends[i], person )\n",
    "            mapperOutput.append( (friends[j], possibleFriend2) ) \n",
    "            \n",
    "    return mapperOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = records.flatMap( make_pairs  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug1 key=1\t value=(2L, -1L)\n",
      "debug1 key=1\t value=(3L, -1L)\n",
      "debug1 key=1\t value=(4L, -1L)\n",
      "debug1 key=1\t value=(5L, -1L)\n",
      "debug1 key=1\t value=(6L, -1L)\n",
      "debug1 key=1\t value=(7L, -1L)\n",
      "debug1 key=1\t value=(8L, -1L)\n",
      "debug1 key=2\t value=(3L, 1L)\n",
      "debug1 key=3\t value=(2L, 1L)\n",
      "debug1 key=2\t value=(4L, 1L)\n",
      "debug1 key=4\t value=(2L, 1L)\n",
      "debug1 key=2\t value=(5L, 1L)\n",
      "debug1 key=5\t value=(2L, 1L)\n",
      "debug1 key=2\t value=(6L, 1L)\n",
      "debug1 key=6\t value=(2L, 1L)\n",
      "debug1 key=2\t value=(7L, 1L)\n",
      "debug1 key=7\t value=(2L, 1L)\n",
      "debug1 key=2\t value=(8L, 1L)\n",
      "debug1 key=8\t value=(2L, 1L)\n",
      "debug1 key=3\t value=(4L, 1L)\n",
      "debug1 key=4\t value=(3L, 1L)\n",
      "debug1 key=3\t value=(5L, 1L)\n",
      "debug1 key=5\t value=(3L, 1L)\n",
      "debug1 key=3\t value=(6L, 1L)\n",
      "debug1 key=6\t value=(3L, 1L)\n",
      "debug1 key=3\t value=(7L, 1L)\n",
      "debug1 key=7\t value=(3L, 1L)\n",
      "debug1 key=3\t value=(8L, 1L)\n",
      "debug1 key=8\t value=(3L, 1L)\n",
      "debug1 key=4\t value=(5L, 1L)\n",
      "debug1 key=5\t value=(4L, 1L)\n",
      "debug1 key=4\t value=(6L, 1L)\n",
      "debug1 key=6\t value=(4L, 1L)\n",
      "debug1 key=4\t value=(7L, 1L)\n",
      "debug1 key=7\t value=(4L, 1L)\n",
      "debug1 key=4\t value=(8L, 1L)\n",
      "debug1 key=8\t value=(4L, 1L)\n",
      "debug1 key=5\t value=(6L, 1L)\n",
      "debug1 key=6\t value=(5L, 1L)\n",
      "debug1 key=5\t value=(7L, 1L)\n",
      "debug1 key=7\t value=(5L, 1L)\n",
      "debug1 key=5\t value=(8L, 1L)\n",
      "debug1 key=8\t value=(5L, 1L)\n",
      "debug1 key=6\t value=(7L, 1L)\n",
      "debug1 key=7\t value=(6L, 1L)\n",
      "debug1 key=6\t value=(8L, 1L)\n",
      "debug1 key=8\t value=(6L, 1L)\n",
      "debug1 key=7\t value=(8L, 1L)\n",
      "debug1 key=8\t value=(7L, 1L)\n",
      "debug1 key=2\t value=(1L, -1L)\n",
      "debug1 key=2\t value=(3L, -1L)\n",
      "debug1 key=2\t value=(4L, -1L)\n",
      "debug1 key=2\t value=(5L, -1L)\n",
      "debug1 key=2\t value=(7L, -1L)\n",
      "debug1 key=1\t value=(3L, 2L)\n",
      "debug1 key=3\t value=(1L, 2L)\n",
      "debug1 key=1\t value=(4L, 2L)\n",
      "debug1 key=4\t value=(1L, 2L)\n",
      "debug1 key=1\t value=(5L, 2L)\n",
      "debug1 key=5\t value=(1L, 2L)\n",
      "debug1 key=1\t value=(7L, 2L)\n",
      "debug1 key=7\t value=(1L, 2L)\n",
      "debug1 key=3\t value=(4L, 2L)\n",
      "debug1 key=4\t value=(3L, 2L)\n",
      "debug1 key=3\t value=(5L, 2L)\n",
      "debug1 key=5\t value=(3L, 2L)\n",
      "debug1 key=3\t value=(7L, 2L)\n",
      "debug1 key=7\t value=(3L, 2L)\n",
      "debug1 key=4\t value=(5L, 2L)\n",
      "debug1 key=5\t value=(4L, 2L)\n",
      "debug1 key=4\t value=(7L, 2L)\n",
      "debug1 key=7\t value=(4L, 2L)\n",
      "debug1 key=5\t value=(7L, 2L)\n",
      "debug1 key=7\t value=(5L, 2L)\n",
      "debug1 key=3\t value=(1L, -1L)\n",
      "debug1 key=3\t value=(2L, -1L)\n",
      "debug1 key=1\t value=(2L, 3L)\n",
      "debug1 key=2\t value=(1L, 3L)\n",
      "debug1 key=4\t value=(1L, -1L)\n",
      "debug1 key=4\t value=(2L, -1L)\n",
      "debug1 key=4\t value=(6L, -1L)\n",
      "debug1 key=1\t value=(2L, 4L)\n",
      "debug1 key=2\t value=(1L, 4L)\n",
      "debug1 key=1\t value=(6L, 4L)\n",
      "debug1 key=6\t value=(1L, 4L)\n",
      "debug1 key=2\t value=(6L, 4L)\n",
      "debug1 key=6\t value=(2L, 4L)\n",
      "debug1 key=5\t value=(1L, -1L)\n",
      "debug1 key=5\t value=(2L, -1L)\n",
      "debug1 key=1\t value=(2L, 5L)\n",
      "debug1 key=2\t value=(1L, 5L)\n",
      "debug1 key=6\t value=(1L, -1L)\n",
      "debug1 key=6\t value=(4L, -1L)\n",
      "debug1 key=1\t value=(4L, 6L)\n",
      "debug1 key=4\t value=(1L, 6L)\n",
      "debug1 key=7\t value=(1L, -1L)\n",
      "debug1 key=7\t value=(2L, -1L)\n",
      "debug1 key=1\t value=(2L, 7L)\n",
      "debug1 key=2\t value=(1L, 7L)\n",
      "debug1 key=8\t value=(1L, -1L)\n"
     ]
    }
   ],
   "source": [
    "debug2 = pairs.collect()\n",
    "for t2 in debug2 :\n",
    "    print \"debug1 key={}\\t value={}\".format( t2[0],  t2[1] ) ; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Implement the reduce() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = pairs.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug2 key=1\t value=(2L, -1L)(3L, -1L)(4L, -1L)(5L, -1L)(6L, -1L)(7L, -1L)(8L, -1L)(3L, 2L)(4L, 2L)(5L, 2L)(7L, 2L)(2L, 3L)(2L, 4L)(6L, 4L)(2L, 5L)(4L, 6L)(2L, 7L)\n",
      "debug2 key=2\t value=(3L, 1L)(4L, 1L)(5L, 1L)(6L, 1L)(7L, 1L)(8L, 1L)(1L, -1L)(3L, -1L)(4L, -1L)(5L, -1L)(7L, -1L)(1L, 3L)(1L, 4L)(6L, 4L)(1L, 5L)(1L, 7L)\n",
      "debug2 key=3\t value=(2L, 1L)(4L, 1L)(5L, 1L)(6L, 1L)(7L, 1L)(8L, 1L)(1L, 2L)(4L, 2L)(5L, 2L)(7L, 2L)(1L, -1L)(2L, -1L)\n",
      "debug2 key=4\t value=(2L, 1L)(3L, 1L)(5L, 1L)(6L, 1L)(7L, 1L)(8L, 1L)(1L, 2L)(3L, 2L)(5L, 2L)(7L, 2L)(1L, -1L)(2L, -1L)(6L, -1L)(1L, 6L)\n",
      "debug2 key=5\t value=(2L, 1L)(3L, 1L)(4L, 1L)(6L, 1L)(7L, 1L)(8L, 1L)(1L, 2L)(3L, 2L)(4L, 2L)(7L, 2L)(1L, -1L)(2L, -1L)\n",
      "debug2 key=6\t value=(2L, 1L)(3L, 1L)(4L, 1L)(5L, 1L)(7L, 1L)(8L, 1L)(1L, 4L)(2L, 4L)(1L, -1L)(4L, -1L)\n",
      "debug2 key=7\t value=(2L, 1L)(3L, 1L)(4L, 1L)(5L, 1L)(6L, 1L)(8L, 1L)(1L, 2L)(3L, 2L)(4L, 2L)(5L, 2L)(1L, -1L)(2L, -1L)\n",
      "debug2 key=8\t value=(2L, 1L)(3L, 1L)(4L, 1L)(5L, 1L)(6L, 1L)(7L, 1L)(1L, -1L)\n"
     ]
    }
   ],
   "source": [
    "debug3 = grouped.collect()\n",
    "for t3 in debug3 :\n",
    "    print \"debug3 key={}\\t value={}\".format( t3[0],  \"\".join([str(x) for x in t3[1]] )   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Generate final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildRecommendations( mutualFriends)  :\n",
    "    from cStringIO import StringIO\n",
    "    strIOs = StringIO()\n",
    "    \n",
    "    for key in mutualFriends.keys() :\n",
    "        values = mutualFriends[key]\n",
    "        if values == None :\n",
    "            continue\n",
    "        \n",
    "        strIOs.write( \"%s(%d:%s),\" \n",
    "                     %(key, len( values ), values)\n",
    "                     )\n",
    "        \n",
    "    return strIOs.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_recommend( values )  :\n",
    "    mutualFriends = {}  # HashMap \n",
    "    for t2 in values :\n",
    "        toUser = t2[ 0 ]\n",
    "        mutualFriend = t2[ 1 ]\n",
    "        alreadyFriend = (mutualFriend == -1L )\n",
    "        \n",
    "        if toUser in mutualFriends :\n",
    "            if alreadyFriend :\n",
    "                mutualFriends[  toUser ] = None\n",
    "            elif mutualFriends[  toUser ] != None :\n",
    "                mutualFriends[  toUser ].append(  mutualFriend )\n",
    "        else :\n",
    "            if alreadyFriend :\n",
    "                mutualFriends[ toUser ] = None\n",
    "            else :\n",
    "                list1 = [ mutualFriend ]\n",
    "                mutualFriends[ toUser ] = list1\n",
    "    \n",
    "    return buildRecommendations( mutualFriends )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommendations = grouped.mapValues( make_recommend )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug4 key=1\t value=\n",
      "debug4 key=2\t value=6(2:[1L, 4L]),8(1:[1L]),\n",
      "debug4 key=3\t value=4(2:[1L, 2L]),5(2:[1L, 2L]),6(1:[1L]),7(2:[1L, 2L]),8(1:[1L]),\n",
      "debug4 key=4\t value=3(2:[1L, 2L]),5(2:[1L, 2L]),7(2:[1L, 2L]),8(1:[1L]),\n",
      "debug4 key=5\t value=3(2:[1L, 2L]),4(2:[1L, 2L]),6(1:[1L]),7(2:[1L, 2L]),8(1:[1L]),\n",
      "debug4 key=6\t value=2(2:[1L, 4L]),3(1:[1L]),5(1:[1L]),7(1:[1L]),8(1:[1L]),\n",
      "debug4 key=7\t value=3(2:[1L, 2L]),4(2:[1L, 2L]),5(2:[1L, 2L]),6(1:[1L]),8(1:[1L]),\n",
      "debug4 key=8\t value=2(1:[1L]),3(1:[1L]),4(1:[1L]),5(1:[1L]),6(1:[1L]),7(1:[1L]),\n"
     ]
    }
   ],
   "source": [
    "debug4 = recommendations.collect()\n",
    "for t4 in debug4 :\n",
    "    print \"debug4 key={}\\t value={}\".format( t4[0],  \"\".join([str(x) for x in t4[1]] )   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MLLIb 활용한 추천\n",
    "\n",
    "[MovieLens](https://movielens.org/) 데이테셋을 사용한 영화추천 예제\n",
    "\n",
    "https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html\n",
    "\n",
    "\n",
    "ratings.dat\n",
    "```\n",
    "UserID::MovieID::Rating::Timestamp\n",
    "```\n",
    "\n",
    "movies.dat\n",
    "```\n",
    "MovieID::Title::Genres\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from os.path import join, isfile, dirname\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseRating(line):\n",
    "    \"\"\"\n",
    "    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return long(fields[3]) % 10, (int(fields[0]), int(fields[1]), float(fields[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseMovie(line):\n",
    "    \"\"\"\n",
    "    Parses a movie record in MovieLens format movieId::movieTitle .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return int(fields[0]), fields[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadRatings(ratingsFile):\n",
    "    \"\"\"\n",
    "    Load ratings from file.\n",
    "    \"\"\"\n",
    "    if not isfile(ratingsFile):\n",
    "        print \"File %s does not exist.\" % ratingsFile\n",
    "        sys.exit(1)\n",
    "    f = open(ratingsFile, 'r')\n",
    "    ratings = filter(lambda r: r[2] > 0, [parseRating(line)[1] for line in f])\n",
    "    f.close()\n",
    "    if not ratings:\n",
    "        print \"No ratings provided.\"\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeRmse(model, data, n):\n",
    "    \"\"\"\n",
    "    Compute RMSE (Root Mean Squared Error).\n",
    "    \"\"\"\n",
    "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
    "    predictionsAndRatings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
    "      .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
    "      .values()\n",
    "    return sqrt(predictionsAndRatings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f09036c5e10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext() \n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))\n",
    "ratings = sc.textFile( \"sample_movielens_ratings.txt\" ).map(parseRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2L, (0, 3, 1.0)),\n",
       " (2L, (0, 5, 2.0)),\n",
       " (2L, (0, 9, 4.0)),\n",
       " (0L, (0, 11, 1.0)),\n",
       " (1L, (0, 12, 2.0)),\n",
       " (2L, (0, 15, 1.0)),\n",
       " (3L, (0, 17, 1.0)),\n",
       " (4L, (0, 19, 1.0)),\n",
       " (5L, (0, 21, 1.0))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.collect()[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# movies is an RDD of (movieId, movieTitle)\n",
    "movies = dict(sc.textFile( 'sample_movielens_movies.txt' ).map(parseMovie).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Movie 1'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1501 ratings from 30 users on 100 movies.\n"
     ]
    }
   ],
   "source": [
    "numRatings = ratings.count()\n",
    "numUsers = ratings.values().map(lambda r: r[0]).distinct().count()\n",
    "numMovies = ratings.values().map(lambda r: r[1]).distinct().count()\n",
    "\n",
    "print \"Got %d ratings from %d users on %d movies.\" % (numRatings, numUsers, numMovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split ratings into train (60%), validation (20%), and test (20%) based on the \n",
    "# last digit of the timestamp, add myRatings to train, and cache them\n",
    "\n",
    "# training, validation, test are all RDDs of (userId, movieId, rating\n",
    "numPartitions = 1\n",
    "training = ratings.filter(lambda x: x[0] < 6) \\\n",
    "      .values() \\\n",
    "      .repartition(numPartitions) \\\n",
    "      .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation = ratings.filter(lambda x: x[0] >= 6 and x[0] < 8) \\\n",
    "      .values() \\\n",
    "      .repartition(numPartitions) \\\n",
    "      .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = ratings.filter(lambda x: x[0] >= 8).values().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 985, validation: 261, test: 255\n"
     ]
    }
   ],
   "source": [
    "numTraining = training.count()\n",
    "numValidation = validation.count()\n",
    "numTest = test.count()\n",
    "\n",
    "print \"Training: %d, validation: %d, test: %d\" % (numTraining, numValidation, numTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train models and evaluate them on the validation set\n",
    "ranks = [8, 12]\n",
    "lambdas = [0.1, 10.0]\n",
    "numIters = [10, 20]\n",
    "bestModel = None\n",
    "bestValidationRmse = float(\"inf\")\n",
    "bestRank = 0\n",
    "bestLambda = -1.0\n",
    "bestNumIter = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (validation) = 1.068924 for the model trained with rank = 8, lambda = 0.1, and numIter = 10.\n",
      "RMSE (validation) = 1.098995 for the model trained with rank = 8, lambda = 0.1, and numIter = 20.\n",
      "RMSE (validation) = 2.248030 for the model trained with rank = 8, lambda = 10.0, and numIter = 10.\n",
      "RMSE (validation) = 2.248030 for the model trained with rank = 8, lambda = 10.0, and numIter = 20.\n",
      "RMSE (validation) = 1.116556 for the model trained with rank = 12, lambda = 0.1, and numIter = 10.\n",
      "RMSE (validation) = 1.091578 for the model trained with rank = 12, lambda = 0.1, and numIter = 20.\n",
      "RMSE (validation) = 2.248030 for the model trained with rank = 12, lambda = 10.0, and numIter = 10.\n",
      "RMSE (validation) = 2.248030 for the model trained with rank = 12, lambda = 10.0, and numIter = 20.\n"
     ]
    }
   ],
   "source": [
    "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
    "    model = ALS.train(training, rank, numIter, lmbda)\n",
    "    validationRmse = computeRmse(model, validation, numValidation)\n",
    "    print \"RMSE (validation) = %f for the model trained with \" % validationRmse + \"rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter)\n",
    "    if (validationRmse < bestValidationRmse):\n",
    "        bestModel = model\n",
    "        bestValidationRmse = validationRmse\n",
    "        bestRank = rank\n",
    "        bestLambda = lmbda\n",
    "        bestNumIter = numIter\n",
    "\n",
    "testRmse = computeRmse(bestModel, test, numTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was trained with rank = 8 and lambda = 0.1, and numIter = 10, and its RMSE on the test set is 1.178326.\n"
     ]
    }
   ],
   "source": [
    "# evaluate the best model on the test set\n",
    "print \"The best model was trained with rank = %d and lambda = %.1f, \" % (bestRank, bestLambda) +  \"and numIter = %d, and its RMSE on the test set is %f.\" % (bestNumIter, testRmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model improves the baseline by 4.53%.\n"
     ]
    }
   ],
   "source": [
    "# compare the best model with a naive baseline that always returns the mean rating\n",
    "meanRating = training.union(validation).map(lambda x: x[2]).mean()\n",
    "baselineRmse = sqrt(test.map(lambda x: (meanRating - x[2]) ** 2).reduce(add) / numTest)\n",
    "improvement = (baselineRmse - testRmse) / baselineRmse * 100\n",
    "print \"The best model improves the baseline by %.2f\" % (improvement) + \"%.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make personalized recommendations\n",
    "myRatings = loadRatings( \"sample_movielens_ratings.txt\" )\n",
    "\n",
    "myRatedMovieIds = set([x[1] for x in myRatings])\n",
    "#candidates = sc.parallelize([m for m in movies if m not in myRatedMovieIds])\n",
    "candidates = sc.parallelize( myRatedMovieIds )\n",
    "predictions = bestModel.predictAll(candidates.map(lambda x: (0, x))).collect()\n",
    "recommendations = sorted(predictions, key=lambda x: x[2], reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=0, product=90, rating=2.7518886987713986),\n",
       " Rating(user=0, product=2, rating=2.5086793021415383),\n",
       " Rating(user=0, product=62, rating=2.318561756589676),\n",
       " Rating(user=0, product=22, rating=2.291471061707517),\n",
       " Rating(user=0, product=9, rating=2.2304497395145106),\n",
       " Rating(user=0, product=81, rating=2.0605470646351933),\n",
       " Rating(user=0, product=77, rating=1.9772180354136948),\n",
       " Rating(user=0, product=68, rating=1.9587252381228097),\n",
       " Rating(user=0, product=32, rating=1.8888954662190125),\n",
       " Rating(user=0, product=12, rating=1.862718519383259),\n",
       " Rating(user=0, product=41, rating=1.7039251158017619),\n",
       " Rating(user=0, product=82, rating=1.6915624171273431),\n",
       " Rating(user=0, product=63, rating=1.6672881334205343),\n",
       " Rating(user=0, product=95, rating=1.5965051870418856),\n",
       " Rating(user=0, product=57, rating=1.5824705802073824),\n",
       " Rating(user=0, product=52, rating=1.5802815549028955),\n",
       " Rating(user=0, product=28, rating=1.5232135324981972),\n",
       " Rating(user=0, product=27, rating=1.4996649971947846),\n",
       " Rating(user=0, product=59, rating=1.4966541839892846),\n",
       " Rating(user=0, product=87, rating=1.4894777262219363),\n",
       " Rating(user=0, product=29, rating=1.481733375821599),\n",
       " Rating(user=0, product=20, rating=1.475383088250684),\n",
       " Rating(user=0, product=93, rating=1.4359559849633774),\n",
       " Rating(user=0, product=37, rating=1.415524436272328),\n",
       " Rating(user=0, product=10, rating=1.4052979513079822),\n",
       " Rating(user=0, product=5, rating=1.4018107020996342),\n",
       " Rating(user=0, product=49, rating=1.3853986554051043),\n",
       " Rating(user=0, product=0, rating=1.3584908769990807),\n",
       " Rating(user=0, product=55, rating=1.3555581857344519),\n",
       " Rating(user=0, product=7, rating=1.3388711352396092),\n",
       " Rating(user=0, product=85, rating=1.3222996821668678),\n",
       " Rating(user=0, product=21, rating=1.3164468086141405),\n",
       " Rating(user=0, product=73, rating=1.305308602067097),\n",
       " Rating(user=0, product=67, rating=1.2901944985473177),\n",
       " Rating(user=0, product=74, rating=1.2674783434263461),\n",
       " Rating(user=0, product=39, rating=1.2469585572535657),\n",
       " Rating(user=0, product=19, rating=1.230132206802375),\n",
       " Rating(user=0, product=36, rating=1.2283704395750563),\n",
       " Rating(user=0, product=88, rating=1.2244513834433346),\n",
       " Rating(user=0, product=56, rating=1.2229183570129845),\n",
       " Rating(user=0, product=4, rating=1.2149195691072998),\n",
       " Rating(user=0, product=14, rating=1.2050856386563773),\n",
       " Rating(user=0, product=11, rating=1.196048984221878),\n",
       " Rating(user=0, product=94, rating=1.1883522662640909),\n",
       " Rating(user=0, product=43, rating=1.159750169033821),\n",
       " Rating(user=0, product=13, rating=1.1584192424284054),\n",
       " Rating(user=0, product=98, rating=1.1572859946932972),\n",
       " Rating(user=0, product=89, rating=1.1552040617076682),\n",
       " Rating(user=0, product=46, rating=1.1230364094924388),\n",
       " Rating(user=0, product=38, rating=1.1051768472467498)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
